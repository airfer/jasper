<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>airfer.github.io/</title>
   
   <link>http://airfer.github.io/</link>
   <description>A beautiful narrative written with the world's most elegant publishing platform. The story begins here.</description>
   <language>en-uk</language>
   <managingEditor> Wang Yukun</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>基于 Docker 的分布式测试系统构建 (二)</title>
	  <link>//pc-ads-distribution-test</link>
	  <author>Wang Yukun</author>
	  <pubDate>2016-05-17T10:18:00+00:00</pubDate>
	  <guid>//pc-ads-distribution-test</guid>
	  <description><![CDATA[
	     <p><strong>前言：</strong>
在基于<a href="https://testerhome.com/topics/6184">Docker的分布式测试系统构建（一）</a>中主要阐述了两个方面的内容，分别为开发此分布式测试系统的缘由以及docker基础镜像的构建和踩过的坑。在本篇中主要有4个部分的内容，分别为分布式测试系统的架构、技术实现细节简述、docker Node节点的部署，以及前端实现。</p>

<blockquote>
  <p>—-  搜狗ADTQ测试组出品</p>
</blockquote>

<hr />

<h2 id="section">一、分布式测试系统的架构</h2>
<p>整体的测试架构主要Docker Nodes节点，Mongodb Broker，Mongodb DB, Front Web，这4个部分构成，其实现的架构简图如下所示：
<img src="/images/pc_ads_distribution/base-framework.jpg" alt="" />
现在就每个部分简要叙述：</p>

<p><em>1. Docker Node节点简述</em>
Docker Node节点主要有Celery 异步框架，Celery Worker任务，Nosetests 测试框架，Mock服务构成。
其分布式实现主要有Celery来完成，通过编写Celery worker 任务来实现具体的测试逻辑。由于业务逻辑本身的需求情况，分层级的调用关系成为实现的有效途径。Celery Worker从Mongodb Broker接收需要完成的任务信息，然后调用Node节点本身的Nosetests框架和Shell脚本，最后调用Mock Service辅助完成测试任务。Celery Worker完成待定的测试任务后，将测试结果写入MongoBD 数据库中以备前端调用。</p>

<p><em>2. Docker Swarm</em>
由于本系统的docker node节点并不多，考虑实现成本以及后续管理难易程度，本系统使用Swarm来管理docker node节点。如果docker node节点众多，可以考虑k8s。关于docker swarm在第二部分会进行说明，这里不在叙述。</p>

<p><em>3. Mogondb</em>
在本系统中，MongoDB主要有两个方面的用途。用途一，作为Celery 的broker，接收前端发送过来的任务请求信息，当broker中有数据时，Celery Worker从broker中获取数据，完成后续任务执行过程；用途二，作为DataBase，Celery worker完成任务后，将result.json数据写入到数据库中</p>

<p><em>4. 前端实现</em>
由于部门内当前的web系统，使用的是Flask Web框架，所以前端主要由Flask + Jquery + Bootstrap实现
整个架构实现还算比较清晰，这对后期的维护也带来了方便。</p>

<h2 id="section-1">二、技术实现有关细节简述</h2>

<p><em>1. 关于使用Celery作为异步框架</em>
由于测试用例本身都是基于python来开发的，并且web系统为Flask，所以有充分的理由选择Celery,关于异步框架的选择可以参考<a href="https://testerhome.com/topics/5732">基于 Docker 集群的分布式测试系统 DDT (DockerDistributedTest)</a>文章中对异步框架的对比。</p>

<p><em>2. 关于Nosetests的插件化</em>
默认安装的nosetests是并未安装json插件的，但是提供xml格式。为了便于后续的结果处理，需要事先安装json插件。这里还有一个小插曲，由于之前从来都是使用默认的插件，都不太清楚原来nosetests也可以私自开发插件并安装，走了不少弯路。当然json的插件不需要自己再重复造轮子，可以直接下载安装。</p>

<p>由于nosetests提供了xml格式报告输出，所以第一时间选择的是xml作为最后的结果报文格式。用到–with-xunit参数，同时需要安装nosexunit插件，但是安装的过程中，需要coverage特定版本的支持，为2.85版本。但是即使安装了2.85版本的支持包，<a href="https://pypi.python.org/pypi/coverage/2.85">https://pypi.python.org/pypi/coverage/2.85</a>也同样会报错。</p>

<p>安装后，使用–with-xunit来运行，会提示如下信息：<em>NameError: global name ‘pylint’ is not defined</em>。但是pylint已经被正确安装，出现这个错误很是匪夷所思。后来以为是nosexunit的版本的问题，现在安装的是最新版本0.3.3，后来换成0.3.2和0.3.1都会出现错误，暂时还没有发现原因。所以最后还是使用json作为结果输出格式。</p>

<p><em>3. 关于测试数据以及环境准备</em>
数据更新以及运行相关环境的准备，总体来说可以有两种大的途径，可总结为远程拉取，和本地挂载。</p>

<p><em>- 远程拉取</em></p>

<p>远程拉取可以有多种方法，第一种为通过rsync方法，将目的机中的数据远程拉取到docker node中，但是由于运行环境的数据量太大，所以当初认为并不可行。经过统计，在内网中完全拉取大小在5.5G左右的文件夹，需要6分钟左右，这个时间太长了。所以当初这个方案是被废弃了。</p>

<p>第二种方法为使用svn或者git，svn的话对于一些特别大的文件，会提示上传受到限制，这种情况下可以使用svn ignore对某些大的文件进行排除，后来发现由于文件夹太大的原因导致svn报错，使用svn ignore属性同样不能解决问题，现在svn报错也还无法查明原因。</p>

<p><em>- 本地挂载</em></p>

<p>通过将所需要的文件传输到docker node宿主机中，然后在运行docker node的时候通过docker -v 本地挂载的形式，可以比较方便的解决环境问题。但是这样会使得部署一个node节点也复杂了一步，必须先同步环境相关数据到docker宿主机，这样又绕回了问题本身。所以本地挂载在本分布式测试系统中并不合适。</p>

<p>所以最后还是要考虑第一个方案。在仔细研究了rsync服务后，发现之前对rsync的研究并不深入，并不清楚rsync的差异性同步模式，通过这篇文章进行了详细的了解，<a href="https://segmentfault.com/a/1190000002427568">https://segmentfault.com/a/1190000002427568</a>，最后决定使用rsync的方式来进行文件同步。
举例如下：
```shell
rsync -auvrtzopgP –progress –delete  –exclude “core.*”   –exclude “your/log” 192.168.56.73::root/the/des/directory/  ./ 
#receiving incremental file list</p>

<h1 id="sent-17376-bytes--received-2397856-bytes--53671822-bytessec">sent 17376 bytes  received 2397856 bytes  536718.22 bytes/sec</h1>
<p>#total size is 17239007382  speedup is 7137.62
```
通过设置–exclude 参数可以将不需要同步的文件排除，比如日志文件，这在实践中很有用</p>

<p><em>4. 关于分布式系统的执行粒度</em>
在第一篇文章中我有提，现在的分布式系统执行的最小粒度是文件，也就是说nosetests 在运行测试程序时，最小是全部执行某一个文件中所有的case。比如A.py文件中有10个cases，而B.py文件有50cases，那么运行过程是node1运行A.py中的所有case，node2运行B.py中的所有cases。由于A.py中的cases比较少，所以node1运行完成后，就闲置了。而总的运行时间有node2来决定，这种情况下系统的资源被浪费了。</p>

<p>当以casesID作为执行的基本单元时，这种情况就不复存在了，假如运行一个case为1分钟，那么原先需要运行50min才能运行完所有的case。而在现有的执行粒度下，只需要30min就可以运行完所有的case。关于python文件中casesID的收集，可以通过nosetests –collect-only命令来进行收集。</p>

<p><em>5. 关于Celery worker的命令</em>
由于每一个cases的运行都需要Mock Service的支持，其主程序在内存中只允许运行一个实例，所以每一个docker node节点每次只可以运行一个case，否则便会相互影响。在解决这个问题的时候走了不少弯路，后来在仔细研究了celery worker的命令后，发现可以通过celery worker的运行时参数就可以控制，当时便有一个柳暗花明又一村的感觉。
举例如下：
<code class="highlighter-rouge">shell
celery -A pc_ads_distribute_worker worker -c 1 --maxtasksperchild=1 -l INFO
</code>
其中的-c参数表示worker并发为1，–maxtasksperchild表示每一个worker最多有几个孩子，同样设置为1，这样就可以满足具体业务测试要求了</p>

<h2 id="docker-node">三、docker node节点部署</h2>

<p>在已经有了docker 镜像后，需要搭建私有的docker registry来方面docker宿主机更新docker镜像，关于docker 私有registry的搭建可以参考如下的网址，这里不再累述了：</p>

<ul>
  <li>
    <p><a href="https://github.com/docker/distribution/blob/master/docs/index.md">https://github.com/docker/distribution/blob/master/docs/index.md</a></p>
  </li>
  <li>
    <p><a href="https://github.com/docker/docker.github.io/blob/master/registry/index.md">https://github.com/docker/docker.github.io/blob/master/registry/index.md</a></p>
  </li>
  <li>
    <p><a href="http://www.open-open.com/lib/view/open1456539405281.html">http://www.open-open.com/lib/view/open1456539405281.html</a></p>
  </li>
</ul>

<p>关于具体的使用方法示例如下：
```shell
#Images查询地址：
curl  http://192.168.56.73:5000/v2/_catalog
#Tags查询：
curl  http://192.168.56.73:5000/v2/pc/centos6.6_base/tags/list</p>

<h1 id="section-2">具体使用方法：</h1>
<p>docker tag centos6.6:program_auto_v3.6 192.168.56.73:5000/pc/program_auto_v3.6
docker push 192.168.56.73:5000/pc/program_auto_v3.6
docker pull 192.168.56.73:5000/pc/program_auto_v3.6
```
由于我测试系统中，并未升级到引擎的1.2.1版本，所以需要下载额外的swarm镜像来完成，关于如何通过swarm来管理docker node镜像由于比较简单，就不多写了，有兴趣的可以参考<a href="http://dockone.io/article/227">http://dockone.io/article/227</a>来配置。</p>

<h2 id="section-3">四、前端部分</h2>

<p>前端的展示主要有三个部分组成，分别为生成分布式任务、测试任务预览、测试任务统计与查询</p>

<p><em>1. 生成分布式任务及测试任务预览</em>
<img src="/images/pc_ads_distribution/distribute_auto_pic1" alt="" /></p>

<p>左边栏包含两个主要部分，分别为填写svn的地址以及上传文件。
svn地址为必填，因为分布式测试任务必须要明确是对svn的哪个版本进行的分布式测试；上传文件为可选，如果不上传文件，则运行所有测试用例，如果上传文件，则只运行上传文件中写明的测试用例文件以及确定的caseid，这个功能在只需要运行测试用例集中的某一个子集时比较有用，右边为生成的任务预览模块，每生成一次任务则新增一条记录。</p>

<p><em>2. 任务执行统计</em>
<img src="/images/pc_ads_distribution/distribute_auto_pic2" alt="" />
这个图比较清楚就不再说明了</p>

<p><em>3. 具体任务查询</em>
<img src="/images/pc_ads_distribution/distribute_auto_pic3" alt="" /></p>

<p>可查询某一次具体的执行情况，必须根据运行的成功还是失败，或者根据具体的文件名来查询都可以</p>

<h2 id="section-4">五、结语</h2>

<p>这两篇算是对之前所做工作的一个总结吧。一天连写两篇，有种写吐了的感觉，好了，就这样吧，希望对各位童鞋有帮助……</p>


	  ]]></description>
	</item>

	<item>
	  <title>测试总结之述职杂谈</title>
	  <link>//summerize-report</link>
	  <author>Wang Yukun</author>
	  <pubDate>2016-05-17T10:18:00+00:00</pubDate>
	  <guid>//summerize-report</guid>
	  <description><![CDATA[
	     <h2 id="section"><strong><em>前言：</em></strong></h2>

<p>最近一段时间一直在忙着平台开发的一些事情，一直都没有时间梳理和总结这过程中的点滴。下个月要准备述职报告，所以就借着这个机会把测试过程中的一些感受记下来，以飨各位看官。本篇是杂谈，所以不谈具体技术，只谈风月。。。</p>

<h3 id="section-1"><strong>一、论工具之稳定性压倒一切</strong></h3>

<p>作为一名测试开发工程师，测试工具应该是非常熟悉了，测试工具是测试过程中的好帮手。好的测试工具对于测试人员效率提升以及减少漏测率都有非常大的帮助。测试工具的来源也有很多，有的工具是较为成熟可以直接拿来用的，有的是基于一些开源的项目然后根据自我需求二次开发的，还有一些是对于某些需求特殊定制的等等，那么对于测试工具什么最重要呢？</p>

<p>从标题可以看出我的结论是，稳定性是一个测试工具最核心的需求。当然这并不是说测试工具的执行效率，测试工具的可扩展性以及可维护性不重要，只是相对于这些特征，稳定性才是一个工具必须要保证的特质。</p>

<p>从半年前的入职到现在，搜狗ADTQ测试组给我留下较深印象之一便是持续集成做的非常出色。因为我所在PC组，所以就以PC组举例。现在PC组对于新增的提测单，除了人工的验证新增功能以及样式展示外，其他的全部交给自动化来执行，包括所有case的分布式执行测试、新旧版本的压力测试、新旧版本的对比测试等等。其中令我吃惊的是这些部署在jenkins上的任务，大多是在2014年就已经完成开发，从2014年到现在一直都在稳定的运行，除了进行必要的维护以及case更新之外，这些工具都表现的非常出色。</p>

<p>这些工具大部分是东哥（暂且这么叫吧^^）开发的，主要通过shell脚本来实现，我和东哥也没见过我入职时东哥已经离职了，但这也不妨碍其所做的工具对我们目前工作的帮助。以case的分布式测试为例，其实现分布式也并非用了非常高深的技术，主要是通过jenkins的api以及shell来完成，就这个看似简单其实并不简单的工具支撑着我们每次上线前的500多个case的回归，帮助我们减少漏测的情况。只要case的分布式执行出现问题，比如突然失败几十个，有可能是功能的漏测，也有可能是合并后的代码有误。</p>

<p>这个分布式case的执行工具之所以可以用的现在，其本身程序的稳定性占有很大的比例，如果一个工具每次的运行都不稳定，或者运行的时候时不时的报个错误，出现个exception，你还会信赖它？还会用它吗？</p>

<p>我所希望的工具就是在我需要它的时候，它能够按时完成我交给它的任务，别给我出乱子，这就足够了。我最讨厌的测试工具就是我一边在使用着这个工具，一边忍受其所报的各种错误提示，对于出现的错误我还要调试半天究竟是什么地方出错了。就是这样一件非常简单的要求，又有多少工具能够很好的满足呢，所以我才要特别强调工具稳定性的重要性，我希望即使我以后离开公司，我的工具也可以在仅有必要维护的情况下能够很好的工作。</p>

<p>最近一段时间做了两个内部使用的平台，其中一个就是开发了新的分布式测试系统，改进了原先分布式测试系统的一些缺点。在试运行阶段，修改了各种bug，现在已经上线并取代原有的分布式测试工具。在开发新的分布式测试系统时，我就感觉到要做好一个工具的稳定性真的非常不容易，需要考虑各种可能的情况，比如一些特殊的输入，执行过程中可能出现的异常，还有case执行过程中的一些特殊的依赖等等。</p>

<p>希望新的分布式测试平台能够发扬老一辈分布式测试系统的优点，将稳定性的核心特质保持下去。这里感谢下东哥，在设计新的测试系统时借鉴了很多老平台的优点。</p>

<p>其实当设计平台将稳定性考虑在内时，你就会考虑更多的东西，比如你的系统需要依赖机子A上的某个文件，如果这种依赖关系是硬编码在代码中，那么极有可能出现A机子文件被删除导致获取失败的情况。这种情况下如果是你自己在维护可能还好，如果你已经离职，新入职的员工如何知道你所依赖的这个文件是什么内容，这种依赖关系是否是必须，这些新员工都不清楚。</p>

<p>如果这种依赖关系是可配置的，不管是通过xml还是json或者web界面，并对这种依赖关系进行详细标注，甚至说明所依赖文件的生成方法，那么这种系统的稳定性以及可维护性就要好很多，甚至不需要去读测试工具的代码就能搞定所出现的问题。关于稳定性还有很多的要求，由于我自己也处在学习阶段，所以就先谈到着吧</p>

<h3 id="section-2"><strong>二、论旧工具与新工具的前世今生</strong></h3>

<p>旧工具可以理解为早些时候开发的工具，这些旧的工具有些可能还在使用，有些可能因为年久失修已经废弃了。当需要这些测试工具所提供的功能时，是继续使用这些即使有些缺点但是还可以使用的旧工具，还是花费大量时间精力去开发新的工具，我相信很多测试同学都有过这种选择，在综合权衡下，做出自己的选择。</p>

<p>我知道肯定也有一些同学与我的想法一致，旧的工具用着不顺，新的工具开发成本又太高，那么就综合两者，以旧工具为蓝本添加新的功能修复原有工具的缺点。当然这三种选择并没有孰优孰劣，能根据具体的测试需求综合权衡，做出正确的选择就好。比如原有的工具实在是太难用，而这个工具开发有比较简单，那么可以考虑重新开发一套，具体情况具体论，切勿盲目追从。</p>

<p>本节所谈论的主要是第三种情况，对现有旧工具进行改造，要不怎么说是前世今生呢，哈哈。还是拿我自己举例吧，现在组内的一些工具，比如性能对比工具，其实现起来比较复杂，首先便是需要搭建一套测试环境，然后再进行对比分析，现有旧的工具也还可以使用，像上一节所谈的，稳定性很好，但就是有些缺点比如生成的报告不直观、调用入口单一（大多数情况通过jenkins平台直接调用）、出错排查不方便等。</p>

<p>如果综合权衡考虑这几方面的因素，会发现改进原有旧工具的缺点，并添加所需要的功能是效率最高的。由于现在ADTQ组有一个统一的测试平台，整合了测试组常用的工具，所以考虑是否能够将原有的jenkins任务整合进现有的平台当中，使得调用更加方便，结果展示更加人性化，错误排查容易呢？通过查询资料以及对旧平台代码的通读，发现改造是可行的，是可以实现的。</p>

<p>由于现阶段还没有进行改进开发，所以就大致说一下我自己改进的思路吧：
1. 关于任务的执行、查询、终止等操作全部通过python版本的jenkins api来完成；</p>

<ol>
  <li>
    <p>修改原有的jenkins任务脚本，添加结果收集模块，将收集的结果写入到数据库中，mysql或者Mongodb都可以；</p>
  </li>
  <li>
    <p>重新开发前端页面，主界面主要有任务触发、结果查看等功能。</p>
  </li>
</ol>

<p>其实这个思路也并不复杂，实现起来的成本也不是很大，主要的工作在于前端页面设计以及和数据库的交互逻辑，这样的改进方法比起重新开发新的工具要省事省力很多。当然也有其他的方法，比如组内的宋大神（非常NB）就利用异步框架Celery加paramiko来实现对脚本的调用，以代替jenkins的工作。改造的方法多种多样，可爱的同学发挥你的聪明才智吧~</p>

<p>旧工具与新工具并非是势同水火的关系，如果能让旧的工具进一步贡献自己的价值那么何乐而不为呢。可能有的同学会问，既然比较推崇对旧工具进行改造，那么你为何又重新开发新的分布式测试平台呢？</p>

<p>其实在本章节我有说过，做出某项选择必然是要经过充分的权衡考虑的，我这里解释一下，旧的平台主要有几个明显的缺点比较难以克服所以才考虑开发新的平台，其一是执行的粒度无法控制，其二是分布式节点部署非常繁琐极易出错。这两点我开发新平台的主要因素，现有的平台在节点部署方面做的非常出色，通过ansible可实现1分钟内将分布式节点由3个扩展到N（具体多少看ansible的性能）个，而旧的平台要实现这样的改进就非常困难，其成本不亚于开发新的平台，所以才考虑开发新的平台</p>

<p>前段时间开发的广告预览平台也是放弃了旧的平台，开发新的平台。之所以做出这样的选择，并非是对旧的平台改造困难，恰恰相反，由于预览平台的技术含量较低，并且有现成的api接口可供调用来完成图片获取，开发的成本较低，同时为了界面更加的友好所以才重新开发。举了这些例子就是想说明，究竟采取那一种方法是需要根据具体情况具体分析的，不能因为某些炫酷的功能而盲目开发新平台，同时也不能因为开发新平台或者改进旧平台的成本太大就放弃努力，得过且过。其实大家都知道我说的是什么意思，这里不再赘述了</p>

<h3 id="section-3"><strong>三、脚踏实地、仰望星空</strong></h3>

<p>温家宝总理说过这样的话：”一个民族有一些关注天空的人，他们才有希望；一个民族只是关心脚下的事情，那是没有未来的”。温家宝总理说这句话时，想表达的是一个国家即需要踏实肯干的人才，也需要有卓越远见，考虑长远的人才。</p>

<p>这句话放在部门内也同样行的通。在当今的社会我们既要做到踏实肯干，同样也需要能跳出当前着眼长远，不要故步自封。如果只是抱着旧的工具方法、旧的流程规章，虽然短期之内并没有大的坏处，但是长久来看，落后是必然的。所以如果有新的想法、新的设计构想、新的技术就要大胆的尝试，虽然不能保证每次尝试都有好的结果，但是如果连努力尝试的想法都没有，一个部门想保持长久的活力也是不可能的。</p>

<p>还是举个例子吧，现在部门内的无线端广告预览只有模拟版本，也就是分辨率可以确定，通过phantomjs来截图。其实都知道如果能实现真机的截图就最好了，考虑很多方面以及testerhome上分享的文章，我们觉得使用stf或许可以完成这样的功能，虽然最后的结果不一定能成，但是尝试又不收费，再说万一要是成了呢。现阶段各种新的技术、新的方法层出不穷，如果能充分利用现有的新技术、新方法，或许可以做到事半功倍。</p>

<h3 id="section-4"><strong>四、论错误排查</strong></h3>

<p>之所以把错误排查单独列出来，是因为我觉得错误排查的能力真的非常非常重要。不管是你自己的程序还是测试工具或者测试环境甚至开发的程序，如果出现了问题，应该知道如何去排查。</p>

<p>现在有些测试同学，都没有自己的测试环境，测试和开发共有一套环境，难道测试的地位真的这么低，都不能有一套独立的测试环境。其实有些时候并非是因为测试地位低，而是测试自己不想去维护这套环境，习惯了只要环境出问题就喊开发来解决，并且认为测试的环境理应当由开发来维护，真不知道为何有这样的想法。如果连维护一套测试环境的能力都没有，还谈什么自动化测试。</p>

<p>我始终相信每个错误的产生必然有其产生的原因。如果一个错误出现了，那么在程序以及资源不发生变化的情况下，其重复出现是必然的。之前出现错误会感到困惑和无奈，而现在则慢慢学会了抽丝剥茧，探索错误产生的根本原因，其实错误排查的过程也充满了乐趣。当然并非每次都是这样，我自己就被一个错误折磨了差不多一个星期，其实差不多都快到崩溃的边缘的，所以耐心也很重要。</p>

<p>举个例子吧，在新的分布式测试系统的实现过程中，就出现了这样一个问题，在docker 节点中通过nosetests来执行case时，有一定的概率server主程序会被杀死，重点就是在这一定概率上，因为对于同一个case有时候server运行是正常的，有些时候则直接被kill掉。我反复将相关的shell以及python脚本通读好多遍，都觉得不应该出现这样的问题。就在我差不多快崩溃的时候，才发现原来node节点中部署了一个case收集程序，这个程序在收集case时会杀掉当前的server程序，由于这是一个crontab任务，所以这才导致了server被杀死的概率性。当时找到这个错误的原因时，真的蓝瘦香菇了。。。</p>

<p>再说一个例子吧，通过docker来部署stf服务的时候，所有都部署完毕，但是stf主程序访问就出现错误，但是stf local程序就可以好好的运行。后来也是经过详细的排查才发现由于stf 容器在vmware虚拟机中运行，而其中的ubuntu虚拟机是采用NAT的方式，这导致了docker0在此网络模式下无法与host进行通信，所以导致无法访问。</p>

<p>举得两个例子是我自己错误排查过程中遇到的两个印象较深的错误，但是好在都找到了原因，其实在错误排查的过程中，你对某程序某方法必要要有很深的了解，要不你怎么排查呢？这样反过来也加深了对某些知识的理解，既解决了问题又涨了知识，这或许是对错误排查过程中所遇到困难的补偿吧。测试同学不要一有问题就找开发了，锻炼一下自己的排错能力吧。。。</p>

<h3 id="section-5"><strong>五、总结</strong></h3>

<p>差不多也就这样了，到今天入职也半年了，点点滴滴都记在心里，整理整理自己的收获、感受、所学也是对过去自己的一个交代。下面是之前发在论坛上的几篇文章，有兴趣的同学可以抽空看看，就到这吧</p>

<ul>
  <li>
    <p><a href="https://testerhome.com/topics/5669">基于 Gtest 的单元测试入门及实践 (一)</a></p>
  </li>
  <li>
    <p><a href="https://testerhome.com/topics/5675">基于 Gtest 的单元测试入门及实践 (二)</a></p>
  </li>
  <li>
    <p><a href="https://testerhome.com/topics/6184">基于 Docker 的分布式测试系统构建 (一)</a></p>
  </li>
  <li>
    <p><a href="https://testerhome.com/topics/6187">基于 Docker 的分布式测试系统构建 (二)</a></p>
  </li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>第十章 轻量级日志监控框架AirMonitor</title>
	  <link>//airMonitor</link>
	  <author>Wang Yukun</author>
	  <pubDate>2016-05-17T10:18:00+00:00</pubDate>
	  <guid>//airMonitor</guid>
	  <description><![CDATA[
	     <h4>一、前言</h4>

<p>点睛Front之前的打点验证，是全部靠人工来解决的，测试人员需要查看具体的打点日志，然后找到相关的日志字段，最后来校验此字段值的正确性。如果说偶尔的类似需求，人工来做校验也未尝不可，但是当需求变更非常频繁时，全靠人工来验证所有日志字段就变得极为耗时和低效。</p>

<p>所以处于对此需求的考虑我们开发了AirMonitor日志监控框架，来对日志字段进行监控，对于校验失败的字段发送报警邮件来通知相关的测试与开发。现阶段此日志监控框架已经部署一段时间，
从监控效果来看，达到了初期预设的目标.</p>

<hr />

<h4>二、AirMonitor日志监控框架图</h4>
<p><img src="\images\ads_plantform_monitor.jpg" alt="" title="轻量级日志监控工具" /></p>

<h4>三、AirMonitor日志监控流程简述</h4>
<ul>
  <li>日志收集端从日志源收集数据，现有框架的日志来源分成两种，一种为日志文件，另一种为Redis。</li>
  <li>日志收集后，需要对收集的日志数据进行过滤清洗，这是清洗脏数据的过程，清洗的具体方式是使用正则匹配表达式进行过滤。</li>
  <li>将清洗后的干净的数据通过HTTP报文发送到规则校验服务器，由规则服务器完成整体的校验过程，并将校验的结果返回给监控服务端</li>
  <li>监控服务端根据监控的类型，将接收到的数据分别写入不同的日志结果文件中，例如Redis_pv,Redis_click等</li>
  <li>通过配置Crontab脚本，定时去扫描所生成的日志结果文件，如果有错误发生，则邮件报警通知，并统计每天所有的扫描数量</li>
</ul>

<h4>四、AirMonitor代码结构简述</h4>

<p><strong><em>监控服务端</em></strong>:</p>

<ul>
  <li>ads_check.js 监控服务端主程序,主要用于收集文件文件以及Redis中的日志数据</li>
  <li>redis_node.js  Node版本的redis客户端，调用redis Monitor服务来监控所有写入redis的日志</li>
  <li>error_check.php  Crontab脚本，用来定时扫描日志结果文件，对于出错的日志字段监控报警通知</li>
  <li>tongji.php  Crontab脚本，每天23：00扫描结果文件，统计每天监控的日志数量</li>
</ul>

<p><strong><em>校验服务端</em></strong>:</p>

<ul>
  <li>click_verify.php  redis click打点校验主程序</li>
  <li>combineLog_verify.php  combineLog日志校验主程序</li>
  <li>e_cheatclick_verify.php e_cheatclick日志文件校验主程序</li>
  <li>pv_verify.php  redis pv打点校验主程序</li>
  <li>后缀为xml格式的文件，为打点主程序的规则配置文件如click_rule.xml、combineLog_rule.xml、combineLog_rule.xml等</li>
</ul>

<h4>五、AirMonitor框架设计思想简述</h4>

<ul>
  <li>
    <h5>模块化设计</h5>
    <p>模块化的设计有助于降低程序的耦合度，便于程序的调试以及扩展，代码逻辑清楚便于维护。在此框架设计中将日志监控的数据
收集端与数据的校验分成两个独立的模块，使得每个模块代码量较少，维护容易，即便是在日志收集端进行进一步的扩展也变得极为方便。</p>
  </li>
  <li>
    <h5>数据驱动</h5>
    <p>在日志数据校验模块，采取了校验主程序与规则数据相互独立的策略，使得对某些字段校验规则的扩展以及变更，无须变更主程序，极大方便了后续人员的维护工作。与此同时对于部分功能测试人员，
此框架的上手也极为简单，不需要去理解主程序的设计逻辑，会使用正则匹配表达式即可</p>
  </li>
  <li>
    <h5>关键词驱动</h5>
    <p>在日志校验模块，除了使用正则匹配表达式完成校验完。还允许测试人员自己定义属于自己的关键词，例如对时间戳字段，我们需要验证其时间必须小于当前时间，则可自定义time关键词来对框架进行扩展，目前只支持php扩展。</p>
  </li>
</ul>

<h4>六、AirMonitor框架的劣势</h4>

<ul>
  <li>
    <p>由于规则校验是搭载到nginx服务器上，所以当此框架在高并发大数据量下无法完成实时的规则校验，可采用ELK技术栈来应对大数据量情况</p>
  </li>
  <li>
    <p>规则校验服务端的设计共享性做的不好，从上述代码结构中看到，每一个日志文件的校验都是由独立的文件来完成整体的校验过程。后续可以在此进行优化，采用工厂模式来统一接口，并使用策略模式区分不同的校验类型，做到模块化更加明显，代码结构更加清晰</p>
  </li>
  <li>
    <p>由于现在关键词驱动是直接整合到主校验程序中，当进行自定义关键词时，需要改动相关的校验主程序，且对于某个主程序的改动无法在各主程序之间共享，这都是下次代码重构需要解决的问题。</p>
  </li>
</ul>


	  ]]></description>
	</item>


</channel>
</rss>
