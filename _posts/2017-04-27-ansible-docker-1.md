---
layout: post
cover: 'assets/images/new-pic-15.jpg'
title: 'Ansible + Docker,只为更好的分布式系统(上)'
date:   2017-03-25 17:19:00
tags: summerize
subclass: 'post tag-test tag-content'
categories: 'casper'
navigation: True
logo: 'assets/images/ghost.png'
---

从最初的V1.0的分布式用例框架，到现在已经发展到V3.0版本，功能已经越来越完善，执行效率相比第一版也有了质的提升。遇见不同，其实就是见证全新的自己，我相信我们在这条道路上会越走越好。

<h4>Poster</h4>
前一段时间，部门内部举办了一场技术开放日活动，我和组内的宋大神，做了关于第三版通用分布式用例框架的Poster，一些同学对我们所做的很敢兴趣，当时因为时间有限，并且人又很多，许多地方讲述的也不太完善。趁着五一之前的少许空闲，把Poster的内容稍微梳理一下，算是我个人对这段时间的一个总结，对可能感兴趣的同学也会有一些帮助。

poster的内容如下图所示：
![](/images/pc_ads_distribution/ansible_docker_framework.jpg)

<h4>我们的痛点和目标</h4>

Poster中列出了V1.0版本，和V2.0版本的痛点，这里简要的说一下。运行时间长，以及分布式节点扩展困难，以及case的粒度无法控制，主要对V1.0来说的。关于详细的一些情况，可以查看之前发的文章。

需要人工选择部署的主机，这个是V2.0版本的遇到的，我们设想的流程是提交任务后，框架自主的从主机列表中选择合适的主机，然后去执行任务，这在V3.0版本已经解决了，虽然方法有些简单，但是也算初步解决了问题，后续在进行完善。

我们的目标其实就是打造通用型、高效的用例执行框架，把其作为服务提供给开发人员和测试人员。V2.0版本虽然初步完成了这个目标，但是由于其和业务联系紧密，扩展性较差，这也是开发V3.0版本的一个原因。

<h4>优势在哪？</h4>

V3.0版本的分布式用例执行框架，优势主要体现在三个方面：

- 更简单：
每一个服务Server，都会有自己独立的一份配置。配置之间的修改也互不影响，初次之外，配置的填写和管理，全部集成在部门内部的测试平台中，只要有相对于的修改权限，都可以修改配置，执行任务。整个过程简单明了

- 更智能：
更智能则体现在主机的分布式节点部署上，通过自有的算法动态的选择主机，然后自主部署，省去了人工选择Host的麻烦，可以做到比人本身更出色的分配，调度能力。目前在分布式节点部署调度上，所试用的规则有三条：
a. 在Host主机中资源满足条件的情况下，优先在已经部署过分布式节点的host上执行部署任务
b. 如果是初次部署任务，优先在资源剩余量最大的Host上部署任务
c. 针对所部署的节点数目以及host资源，完美拆分后部署（目前还不支持）

对于规则a的规定，其实是和业务紧密联系的。由于我们容器需要加载的文件太大，所以拖取需要加载的文件需要花费大量的时间，所以在host主机资源允许的情况下，尽量在已经部署过节点的主机上部署

和一般分布式框架不同，本分布式用例框架采用异步抢占式的调度策略，关于该抢占策略的实现，主要是借助Celery来完成的。在之前介绍V2.0版本的时候已经做了阐述，这里不细说了。

- 更高效：
更高效体现在一台主机，可以同时运行多个服务实例，相比于V1.0版本，case的执行效率可以成倍提升。V2.0版本已经实现了这一方法，在V3.0版本中继承了V2.0版本中优势的地方。

<h4>Why Ansible ?</h4>

Ansible的好处在poster中已经列出来了，之前我对ansible也不熟悉，但是用过之后发现真的非常方便。由于是Agentless框架，所以无需在被操控的主机上安装客户端。

现在我们做到一套服务，一份配置，说的更明白一点，这份配置就是ansible的 playbook脚本，而动态主机信息的获取也主要是通过Ansible的动态Inventory来实现的。配置信息填写界面如下图所示：

这一点和V2.0版本有显著的不同，在V2.0版本中，任务资源获取、加载、执行，完全是整合在一起。没有使用Ansible来进行任务信息，主机资源信息的收集和管理，这也导致了业务和框架的耦合度太高，迁移到其他业务的成本太大，也是做V3.0的根本原因

在技术分享日的当天，有很多的同学问我，为啥选择ansible而不选择SaltStack等工具呢？其实我没有使用过SaltStack，在网上看到对比说，SaltStack的执行效率要比Ansible高，但是由于我们是测试环境下部署，对于执行效率并没有太高的要求；再者部门内宋大神使用Ansible已经很长时间了，现有的很多服务部署执行，都是基于Ansible来做的，所以在执行工具的选择上就选择了Ansible。除此之外，ansible对docker支持良好，这也是一个非常重要的原因。

所以，是不是选择Ansible还是要具体情况具体分析。

<h4>Why Docker ?</h4>

选择docker的原因，在前几篇的文章中已经分析过了。poster中简单的列了几条，之前由于只在PC业务中使用docker，所以维护一份镜像就够了。现在为了适应不同的业务线，我们做到了一份服务（一个server），一份镜像，根据业务需求进行定制。将构建好的镜像推送的私有的Docker Registry中，需要部署任务的时候从中拉取，方便管理且高效

每一次运行任务，都会重新启用新的容器，由于容器之间不需要相互通信，所以全部都使用bridge模式，运行一次构建一次，运行结束后就删除容器，释放计算机资源，这样真正的做到了任务之间的互相不影响。

只要计算机资源允许，可以在同一主机上运行多个服务实例，这相当于将一台主机当几台来用，不但提高了执行效率，还充分利用了现有的计算机资源。

关于docker在分布式用例系统中的具体应用，如果感兴趣，可以阅读以下之前发的相关文章，关于docker就说到这吧

<h4>后记</h4>

V3.0版本已经解决了很多问题，但是仍有很多问题没有解决，poster中也列出了2点。这都在后续完善的范畴之内。在分享日的当天，有些同学问了我这样一个问题，如果容器之间需要相互通信该怎么办呢？其实在此之前我都没有仔细考虑过这个问题，由于我们的部署在容器中的服务，不需要在容器之间相互通信，其所依赖的其他服务全部都是Mock桩并集成在单个容器中。所以对于容器之间相互通信的解决方案，我想了几个，可能不是很完善，发出来，全当同学们之间交流了

- 像目前我所做的，如果其依赖的都是Mock桩，那么可以将其集成在单个容器中，这样就绕过了容器之间通信的问题
- 如果所依赖的都是真实的服务，如果自己实现容器的调度，可以通过host模式以及端口映射来解决，但是其访问的规则也要在配置文件中写清楚防止混乱
- 如果系统是centos7等高版本系统，可以使用一些容器编排工具，包括新版的swarm或者k8s，我自己没有使用编排工具进行过分布式用例系统设计，所以更多的建议我也无法给出了

其实本篇只是梳理了一下poster的内容，对一些内容作了进一步阐释，在下篇中会讲述playbook脚本文件实现，以及集成于镜像文件中的unicorn（独角兽）工程。测试，遇见不同，遇见不同的自己。

最后欢迎关注我们的微信公众号"铸盾师"

