---
layout: post
cover: 'assets/images/new-pic-18.jpg'
title: 'kubernetes在测试中的应用实践'
date:   2017-08-29 19:28:00
tags: 	docker
subclass: 'post tag-test tag-content'
categories: 'casper'
navigation: True
logo: 'assets/images/ghost.png'
---
<h4>前言</h4>
在休假之前就想写一写kubernetes在测试中应用的一些事，后来因为各种原因被耽搁了下来。这次趁着休假期间的空闲，把应用方面的东西梳理一下，算做是对之前一段研究东西的总结。

研究kubernetes也有一段时间了，在测试方面的应用我将其归类为三个方面：分别为服务部署、环境搭建、持续集成优化 。其实每个方面都值得写一篇文章进行详细阐述，只是最近变的有些懒，就写个总的概况吧。对这个方向感兴趣的同仁欢迎拍砖，也欢迎大家留言探讨，正餐现在开始。

<h4>服务部署</h4>
服务部署作为k8s最主要的核心功能，在实践中被广泛应用是一件很正常的事情。其实这里讲的服务部署，主要是测试服务的部署，当然这和其他服务的部署没有本质的区别。这样做的目的是充分利用k8s集群的特性为我们服务，保证我们测试服务稳定且高效。目前我们的k8s集群上部署了两个服务，一个是jenkins，一个是镜像生成服务takara。就以takara为例来举例说明吧。

首先介绍一下takara，takara服务是根据用户提供的dockerfile文件生成image镜像，并将镜像推送到本地私有registry，成功后返回生成的镜像信息供后续部署使用。其工作原理如下图所示：
![](/images/k8s/takara.jpg)

takara作为基础服务存在，如果其出现问题将影响后续所有的部署、构建过程，所以其必须稳定。后续由于多个业务线会使用该服务，为了高效快速的生成镜像减少排队情况的发生，Image 生成器会有多个。

从图中可以看出，HttpServer接受get/post的请求，请求的信息中包含dockerfile的地址信息、所需的依赖文件信息等。关于所依赖的物料数据来源有多种方式，例如使用rsync工具，或者直接从hadoop上获取。HttpServer的作用在于解析请求数据，并将解析后的数据写入任务调度队列，供后续worker使用。

由于worker生产镜像的过程是无状态的，所以可以通过kubernetes的replica set动态调整worker的数目。每一个worker位于一个pod中，由两个container组成，分别为Prepare container和Generate container。

前者用于docker build之前的准备工作，主要是获取dockerfile文件，以及相关的依赖文件，并将获得的文件数据进行持久化存储。当前持久化存储使用的是nfs，目前在测试环境下支持良好，速度较快。后者用于根据获取的dockerfile文件数据，生成image镜像，并将镜像重新命名，打tag后推送到私有的镜像仓库，供后续使用。

由于httpserver的上层是kubernetes的service，所以即使一个httpserver挂掉，也不会影响整体的运行。httpserver的数量以及worker的数量都通过replica set进行控制。可以发现，使用kubernetes进行服务部署的好处在于服务的稳定高效，无状态扩展简单。并不是所有的服务都适合在kubernetes上部署，具体情况需要具体分析。
环境搭建
在测试过程中，环境搭建是一个比较头疼的事情，各种操作系统的版本，各种依赖库，每一次搭建都要重复一遍这个痛苦的过程。那么有没有一种方法可以一劳永逸呢？其实答案就是镜像。我们将各种操作系统的版本以及服务运行所依赖的lib库生成一个镜像，然后将镜像上传到我们的私有registry，每次在使用的时候直接从registry中拖取就可以了。

这样看来是非常简单的事情，那么这和kubernetes有什么关系呢?我们安装docker直接pull不可以吗？其实在实际应用中会发现遇到的问题比刚开始所想的要多的多。那么考虑下面几个方面：
- 如果开发同学想要一个环境，但是没有空闲的机器
- 如果你在本地环境发现某问题，如何让开发快速的定位修复
- 如何和同组的其他同学分享你的测试环境
- 当测试环境很多时，如何有效的管理这些环境
- 当测试环境由于一些因素挂掉时，如何保证稳定可用

通过上述的问题，我们发现要满足上面的几个方面，需要保证以下几点：
- 非初次环境的部署要快速，不能部署一个环境需要半天甚至更长的时间
- 环境需要有独立的ip，可以通过ssh访问，便于开发定位问题
- 当环境很多时，需要有一个列表或者table列出环境与ip的对应关系，方便查找
- 当环境因某些原因挂掉时，可以自行重启恢复，重启后数据不丢失
目前部门内部试用的环境部署方案如下图所示：
![](/images/k8s/ssh.jpg)
从图中可以看出，整体的结构比较简单，其实环境部署的重点在于镜像制作。用户通过ssh登录到中控机，然后在中控机上通过ssh免密码登录所需服务。但是这里需要对以下几点进行说明：
- 由于集群内部中pod的ip为weave overlay网段私有ip地址，所以在公司内网中是无法直接访问。为了解决这个问题，一种方式是将镜像中的sshd服务通过service开放出来，这样通过访问service可以访问sshd服务，但是这种方式存在一些问题，比如在内网中存在external ip无法获取的情况
- 另一种方式，将kubernetes集群中的一个node作为中控节点，通过在中控节点访问kubernetes内部的pod，目前部门内部采用的是这种方式。这种方式相比第一种方法，比较简单不需要配置service，同时也起到了一定的安全保护作用（只可从中控机访问）
- 每个需要启动的环境镜像，都包含了中控机的ssh公钥信息，这样可以做到免密码登录
- 至于查看环境与ip的对应关系，通过kubernetes的dashboard或者在master节点上查看都可以，不过推荐dashboard

<h4>持续集成优化</h4>
持续集成一直是测试关注的重点，在持续集成的实践中，我们也碰到了一些问题。比如，我们需要选择具体在某个jenkins slave node中执行我们的程序，由于程序的执行对操作系统以及相关的依赖库都有要求，所以在运行jenkins任务之前，我们必须保证slave节点已经配置了任务要求所有的要素。

每新增一个slave节点，上述的环境配置都需要重新配置，很耗费时间。同时如果我们的slave节点挂掉了，我们需要去重新启动这个节点；如果这个节点已经下线，那么就需要重新申请一个节点，或者将该任务的执行节点重新迁移到新的节点。

当任务不多，并且节点变动不是很频繁时，这个需求并不是很强烈。但是当支持的业务线众多，各服务依赖的操作系统以及相关库差异性很大时，基于容器的持续集成就变得优势巨大。每个业务线都可以根据自己的需求定制自己的镜像，持续部署时依赖自己的镜像就可以了。

举个例子，假设有5台slave机子都安装了某依赖库，后来由于服务升级，该依赖库也需要进行升级。如果按照传统的方法，需要分别到这5台机子上进行升级，而如果使用镜像，只需要重新生成镜像即可。

使用kubernetes集群进行持续集成最大的优点就是解决了环境依赖问题，最终这个任务究竟在哪个node，哪个pod中运行，根本无需担心。目前基于kubernetes集群的持续集成有两个方式：
一种是直接在master节点上按照pipeline的stage执行程序，程序直接在master节点上执行，和服务部署相同，程序运行结束，pod就终止被删除。
另一种方式，是利用jenkins的kubernetes插件，关于其使用说明github中的文档已经写的很清楚了，就不再赘述了。

关于pipeline的使用并不是本篇讨论的重点，后续@宋大神会专门写一篇文章介绍。

这里以目前的竞价服务的pipeline进行简要的说明。对于竞价服务，和其他服务一样，我们需要一个完整的持续集成体系。在这个持续集成的pipeline中，包含代码静态检测、分布式功能性测试、增量式性能测、手工功能性测试，示意图如下所示：
![](/images/k8s/pipeline.jpg)
从图中可以看到代码的静态检测用的cpplint以及infer，后续会写一个这两个工具的对比分析；分布式功能性测试除了完成全部的自动化case回归之外，还包括代码的覆盖率统计，用的是gcov；增量式压测用的是部门内部已存在的压测工具端；手工功能测试，使用第二部分的环境进行测试即可。

这里重点说一下增量式压测，压测的目的是检查程序运行的稳定性以及是否存在内存泄露等问题。目前的压测环境用的线上拷贝的全量数据，而压测端用的是从线上截取的部分数据，比如从线上截取20000条。这样就存在一个问题，由于压测端的数据并不具有特异性，无法重点覆盖新增加的功能。考虑一种极端的情况，使用的这20000条数据，得到是同样的样式数据，这样就无法做到覆盖尽可能多的分支。

而分布式回归测试中，自动化case都是具有特异性的，就是为了验证某项功能，那么可不可以将分布式回归的case经过一些修改用于增量式压测呢？其实这个方案是可行的，在休假之前，我已经在物料库测试中进行了验证。假设在物料库服务中的新增代码中存在内存泄露，那么某个自动化case恰好覆盖这个代码分支，那么反复运行该case，内存泄露的情况从kubernetes的node节点中是可以明显查看到的。

由于heapster以及grafana的存在，使得监控pod以及报警变得更加简单，关于其实现机制有兴趣的同学可以去github中查看，下面的例子是当时测试过程中的截图，如下所示：
![](/images/k8s/material1.jpg)
图一
![](/images/k8s/material2.jpg)
图二
其实并不是需要运行几个小时甚至一天才能查看到内存是否泄漏，从上面的两个图可以看到即使很短的时间，或许只要几分钟我们也可以看到内存持续增长的趋势。

<h4>后记</h4>
这篇的内容其实是对之前我所做工作的一个梳理，虽然休假之前就想写一写，但是感到头疼，因为涉及的点太多，感觉无从下手。本篇也只是写了一个概览，有很多细节并未提及，希望本篇能给还在这条路上探索的同学一点启发。

很多时候我一直在想提高测试生产力的方法，其实到最后可归为两类，一类是测试技术能力的提升，比如本篇所提及的；另一类则是测试策略。之前写过一些总结类的文章，基本都会涵盖一些测试策略、测试方法。测试的策略与方法并非一成不变的，好的测试工程师应该可以根据业务的需求，定制合适的测试方案。

本篇就到这吧，最后欢迎关注我们的微信公众号，铸盾师~~
